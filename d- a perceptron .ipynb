{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd    #importing librabies needed\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Perceprton: \n",
    "    #def _init (self, learning_rate=0.01, n_iter=1000):\n",
    "     #   self.lr = learning_rate\n",
    "      #  self.n_iter = n_iter \n",
    "       # self.activation_func = self.unit_step_func\n",
    "        #self.weights = None \n",
    "        #self.bias = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fit(self, x):\n",
    " #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def unit_step_func(self,x):\n",
    " #   return np.where(x>=0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predict(self,x):\n",
    " #   linear_output= np.dot(x, self.weights) + self.bias \n",
    "  #  y_oredicted = self.activation_func(linear_output)\n",
    "   # return y_predicted \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('train_1.csv')        #reading the training file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = file.iloc[:,-1:]               #splitting the last column from the training set (the result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = file.iloc[:,:-1]               #splitting features columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per.fit(x_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_with_label_1.csv')    #reading the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.iloc[:,:-1]             #splitting features columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.iloc[:,-1:]             #splitting the last column from the test set (the result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 22,  2, 18, 17, 18, 23, 22, 20,  2,  9, 11, 24,  4,  5,  6,  8,\n",
       "        2, 12, 16,  0, 25, 17,  9,  1, 21,  8, 23,  8,  3, 23, 10, 16, 10,\n",
       "       23,  6, 19, 15,  3, 16, 11, 13,  1, 13,  7, 10, 14, 24,  0,  7,  3,\n",
       "       22, 20,  3, 14, 25,  9, 17, 14,  7,  2, 11,  7, 22,  6,  6, 20, 12,\n",
       "        1, 24, 22, 21,  8, 22, 18, 15, 17,  6, 19], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_pred = per.predict(x_test)\n",
    "per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       0.80      1.00      0.89         4\n",
      "           7       0.50      0.67      0.57         3\n",
      "           8       0.75      1.00      0.86         3\n",
      "           9       1.00      0.75      0.86         4\n",
      "          10       0.33      0.33      0.33         3\n",
      "          11       1.00      0.75      0.86         4\n",
      "          12       0.50      0.33      0.40         3\n",
      "          13       1.00      0.75      0.86         4\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      0.67      0.80         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       0.75      0.75      0.75         4\n",
      "          18       0.67      0.67      0.67         3\n",
      "          19       0.50      0.50      0.50         2\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      0.67      0.80         3\n",
      "          22       0.50      1.00      0.67         3\n",
      "          23       0.50      1.00      0.67         2\n",
      "          24       0.67      0.67      0.67         3\n",
      "          25       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.77        79\n",
      "   macro avg       0.80      0.78      0.77        79\n",
      "weighted avg       0.82      0.77      0.77        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,per_pred))   #generating the report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix= (confusion_matrix(y_test,per_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,per_pred))    #generating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
